{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "5c5a2d0d-e544-4e63-a4f4-15a89c4f1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "from time import gmtime, strftime\n",
    "import datetime\n",
    "from keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "54d07d7f-0978-473e-aa1f-a68e2f61dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 1000\n",
    "BATCH_SIZE = 100\n",
    "VERBOSE = 0\n",
    "NB_CLASSES = 1 # Survived\n",
    "OPTIMIZER = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.1 # how much TRAIN is reserved for VALIDATION\n",
    "RESHAPED = 784\n",
    "DROPOUT = 0.3\n",
    "REGULARIZER=regularizers.l2(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "403a4a09-9af0-4e8f-b472-5ac47761f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titanic_train.csv')\n",
    "df\n",
    "df_test = pd.read_csv('data/titanic_test.csv')\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "2622fea0-aae5-467e-a953-6352831dac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'] = df['Cabin'].fillna('CABIN-NULL')\n",
    "df['Embarked'] = df['Embarked'].fillna('EMBARKED-NULL')\n",
    "\n",
    "df_test['Cabin'] = df_test['Cabin'].fillna('CABIN-NULL')\n",
    "df_test['Embarked'] = df_test['Embarked'].fillna('EMBARKED-NULL')\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "df['Sex'] = labelEncoder.fit_transform(df['Sex'])\n",
    "df_test['Sex'] = labelEncoder.transform(df_test['Sex'])\n",
    "# labelEncoder1 = preprocessing.LabelEncoder()\n",
    "# labelEncoder2 = preprocessing.LabelEncoder()\n",
    "# labelEncoder3 = preprocessing.LabelEncoder()\n",
    "# df['Sex'] = labelEncoder1.fit_transform(df['Sex'])\n",
    "# df['Cabin'] = labelEncoder2.fit_transform(df['Cabin'])\n",
    "# df['Embarked'] = labelEncoder3.fit_transform(df['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "b7736318-4749-4e55-9231-5c78f70f5510",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncoder1 = preprocessing.OneHotEncoder(categories='auto', sparse=False)\n",
    "oneHotEncoder1.fit(pd.concat([df['Cabin'],df_test['Cabin']]).values.reshape(-1, 1))\n",
    "cabin = oneHotEncoder1.transform(df['Cabin'].values.reshape(-1, 1))\n",
    "arrays = oneHotEncoder1.categories_\n",
    "\n",
    "series = pd.Series(arrays[0], dtype=str)\n",
    "lists = series\n",
    "\n",
    "cabin = pd.DataFrame(cabin, columns=lists)\n",
    "# cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "3524992a-8ea5-458e-8cad-29349e9cbbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_test = oneHotEncoder1.transform(df_test['Cabin'].values.reshape(-1, 1))\n",
    "arrays = oneHotEncoder1.categories_\n",
    "\n",
    "series = pd.Series(arrays[0], dtype=str)\n",
    "lists = series\n",
    "\n",
    "cabin_test = pd.DataFrame(cabin_test, columns=lists)\n",
    "# cabin_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "1ad50f2b-1843-4598-bcc5-cf99f26ca4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncoder2 = preprocessing.OneHotEncoder(categories='auto', sparse=False)\n",
    "oneHotEncoder2.fit(pd.concat([df['Embarked'],df_test['Embarked']]).values.reshape(-1, 1))\n",
    "embarked = oneHotEncoder2.transform(df['Embarked'].values.reshape(-1, 1))\n",
    "arrays = oneHotEncoder2.categories_\n",
    "series = pd.Series(arrays[0], dtype=str)\n",
    "lists = series\n",
    "\n",
    "embarked = pd.DataFrame(embarked, columns=lists)\n",
    "# embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "dd719326-f576-4d48-8c45-1b6abc73d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_test = oneHotEncoder2.transform(df_test['Embarked'].values.reshape(-1, 1))\n",
    "arrays = oneHotEncoder2.categories_\n",
    "series = pd.Series(arrays[0], dtype=str)\n",
    "lists = series\n",
    "\n",
    "embarked_test = pd.DataFrame(embarked_test, columns=lists)\n",
    "# embarked_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "b5982871-3543-41be-ad52-18809539bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, cabin, embarked], axis=1)\n",
    "df_test = pd.concat([df_test, cabin_test, embarked_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "191ebc0c-de13-4221-b54a-41696aec2a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'A10', 'A11', 'A14',\n",
       "       'A16',\n",
       "       ...\n",
       "       'F2', 'F33', 'F38', 'F4', 'G6', 'T', 'C', 'EMBARKED-NULL', 'Q', 'S'],\n",
       "      dtype='object', length=197)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = df.columns\n",
    "col = col[col != 'Survived']\n",
    "col = col[col != 'PassengerId']\n",
    "col = col[col != 'Name']\n",
    "col = col[col != 'Ticket']\n",
    "col = col[col != 'Cabin']\n",
    "col = col[col != 'Embarked']\n",
    "col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f2be5456-b988-4d16-9e5c-5e557b8fed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "4b3e3b22-456b-493e-bb8e-d7205ffe61e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.array(df[col].fillna(0))\n",
    "y_np = df['Survived'].values\n",
    "\n",
    "X_submit = np.array(df_test[col].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "cb64a351-9e2f-4179-ba67-cd05fc55cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "02aa433e-2466-4834-b73e-89b44b9e91cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_114 (Dense)           (None, 128)               25344     \n",
      "                                                                 \n",
      " activation_113 (Activation)  (None, 128)              0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " activation_114 (Activation)  (None, 128)              0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " activation_115 (Activation)  (None, 128)              0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_116 (Activation)  (None, 1)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,497\n",
      "Trainable params: 58,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, kernel_regularizer=REGULARIZER, input_shape=(197,)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "#model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(N_HIDDEN, kernel_regularizer=REGULARIZER))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "#model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(N_HIDDEN, kernel_regularizer=REGULARIZER))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "0e7964e9-0770-4e3c-8be7-dc52673c224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "255e82c5-9041-4fae-9846-3fc9ada313fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.fit(X_train, y_train,\n",
    "batch_size=BATCH_SIZE, epochs=epochs + NB_EPOCH,\n",
    "initial_epoch=epochs,\n",
    "callbacks=[tensorboard_callback],\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "epochs += NB_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "25175535-6ea5-4fee-ba4a-1569e9318114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.3379055857658386\n",
      "Train accuracy: 0.8838951587677002\n",
      "Test score: 0.47415390610694885\n",
      "Test accuracy: 0.8444444537162781\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=VERBOSE)\n",
    "print(\"Train score:\", score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a90a198c-34be-4aa4-be96-87a456e6694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.47332677245140076\n",
      "Train accuracy: 0.7994012236595154\n",
      "Test score: 0.5273887515068054\n",
      "Test accuracy: 0.7578475475311279\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=VERBOSE)\n",
    "print(\"Train score:\", score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55445c8-b57a-4f70-b2f4-b7dec802b5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "39cdc48b-5058-465f-a47b-d663948cbc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = model.predict(X_submit, batch_size=BATCH_SIZE, verbose=VERBOSE, steps=None).round()\n",
    "submit = pd.DataFrame({'PassengerId':df_test['PassengerId'],\n",
    "              'Survived':survived.reshape(418)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "4ededa47-e456-4db0-b8f9-dab4c14687e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['Survived'] = submit['Survived'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "fd00bca8-97e3-4cfd-9795-2340bd2e40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"output/titanic_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c013c5-9e05-4970-b964-bf5e693da9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc3b5f-4511-4594-aa72-645c40a8c36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb7495-5e05-4259-b466-e54ec6a9ef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
